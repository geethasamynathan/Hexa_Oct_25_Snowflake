
# 🧊 Snowflake Trainer Notes — Subset Column Loads & Auto-Increment IDs with `COPY INTO`

This guide explains what each statement does, why it’s written that way, and common pitfalls.  
We’ll cover:
- Creating a table
- Loading **only a subset of columns** from a staged CSV
- Using an **auto-increment** (identity) column and how `COPY INTO` behaves with it
- Verifying results and clean-up

---

## ✅ Prereqs (context for all examples)

- A running **warehouse** (to execute `COPY INTO`).
- You have a working **external stage** at `@MANAGE_DB.external_stages.aws_stage` pointing to the file(s) (e.g., `OrderDetails.csv`).
- The file is **CSV**, **comma-delimited**, with **header** on the first line.

> Tip: Positional columns `s.$1`, `s.$2`, `s.$3`, … refer to the 1st, 2nd, 3rd fields of the parsed CSV row.

---

## Example 3 — Create the base table

```sql
CREATE OR REPLACE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX (
    ORDER_ID         VARCHAR(30),
    AMOUNT           INT,
    PROFIT           INT,
    PROFITABLE_FLAG  VARCHAR(30)
);
```

### What this does
- Creates (or replaces) a table named **`ORDERS_EX`** with 4 columns.
- **Data types**:
  - `ORDER_ID` is **text** here (not numeric).
  - `AMOUNT` and `PROFIT` are **INT** (whole numbers).
  - `PROFITABLE_FLAG` is **text**, e.g., `'Y'/'N'`, `'TRUE'/'FALSE'`, etc.

### tips
- If your CSV has **decimals** for amount/profit, change types to `NUMBER(10,2)` (or cast during `COPY`).
- If you “replace” an existing table, **all rows are dropped** and structure is reset.

---

## Example 4 — Load a **subset of columns** from the file

```sql
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX (ORDER_ID, PROFIT)
FROM (
  SELECT 
    s.$1,    -- ORDER_ID from CSV col 1
    s.$3     -- PROFIT   from CSV col 3
  FROM @MANAGE_DB.external_stages.aws_stage s
)
FILE_FORMAT = (TYPE = CSV FIELD_DELIMITER=',' SKIP_HEADER=1)
FILES = ('OrderDetails.csv');

SELECT * FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;
```

### What this does
- Loads **only two columns** into the target table: **`ORDER_ID`** and **`PROFIT`**.
- The `SELECT` produces **two fields** (`$1` and `$3`) which map **by position** to the two listed target columns.
- **`AMOUNT`** and **`PROFITABLE_FLAG`** will be **NULL** for the loaded rows because you didn’t load them.

### Why it’s useful
- Real files often contain more columns than you need, or you want to **load incrementally** (subset now, rest later).
- You control the **source→target mapping** and can add **transforms** in the `SELECT`.

### Recommended “safer” pattern (casts)
```sql
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX (ORDER_ID, PROFIT)
FROM (
  SELECT 
    TRIM(s.$1)                      AS ORDER_ID,
    TRY_TO_NUMBER(s.$3)             AS PROFIT
  FROM @MANAGE_DB.external_stages.aws_stage s
)
FILE_FORMAT = (TYPE = CSV FIELD_DELIMITER=',' SKIP_HEADER=1)
FILES = ('OrderDetails.csv')
ON_ERROR = 'CONTINUE';  -- optional: skip bad rows and review rejects
```

> **Casting matters:** CSV fields are read as strings. Cast to numeric/date types explicitly to avoid implicit-cast surprises.

---

## Example 5 — Use an **auto-increment** (identity) column

### 5a) Recreate table with `ORDER_ID` as identity
```sql
CREATE OR REPLACE TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX (
    ORDER_ID        NUMBER AUTOINCREMENT START 1 INCREMENT 1,
    AMOUNT          INT,
    PROFIT          INT,
    PROFITABLE_FLAG VARCHAR(30)
);
```

#### What this means
- `ORDER_ID` will be **auto-generated**: `1, 2, 3, ...` as rows are inserted.
- You **can** still insert explicit values into an identity column in Snowflake if you list it, but if you **omit** it from the target column list in `COPY`, Snowflake **generates** it.

### 5b) Load only `PROFIT` and `AMOUNT`, let `ORDER_ID` auto-generate
```sql
COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX (PROFIT, AMOUNT)
FROM (
  SELECT 
    s.$2,   -- PROFIT from CSV col 2
    s.$3    -- AMOUNT from CSV col 3
  FROM @MANAGE_DB.external_stages.aws_stage s
)
FILE_FORMAT = (TYPE = CSV FIELD_DELIMITER=',' SKIP_HEADER=1)
FILES = ('OrderDetails.csv');

SELECT * 
FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX 
WHERE ORDER_ID > 15;
```

### Mapping & behavior
- **Target column list** is `(PROFIT, AMOUNT)` → 1st selected field goes to `PROFIT`, 2nd to `AMOUNT`.
- `ORDER_ID` is **not** listed ⇒ Snowflake auto-generates it.
- `PROFITABLE_FLAG` stays **NULL** unless provided or derived.

### Trainer tips
- Ensure your **source positions** match your target order. If the CSV layout changes, update `s.$N` mapping.
- Prefer **explicit casting**:
  ```sql
  COPY INTO OUR_FIRST_DB.PUBLIC.ORDERS_EX (PROFIT, AMOUNT)
  FROM (
    SELECT 
      TRY_TO_NUMBER(s.$2) AS PROFIT,
      TRY_TO_NUMBER(s.$3) AS AMOUNT
    FROM @MANAGE_DB.external_stages.aws_stage s
  )
  FILE_FORMAT = (TYPE = CSV FIELD_DELIMITER=',' SKIP_HEADER=1)
  FILES = ('OrderDetails.csv');
  ```

### Why `WHERE ORDER_ID > 15`?
- After loading, this filters rows with **auto-generated IDs** greater than 15.
- Useful to validate later loads or to check “batches” of newly created rows.

---

## ✅ Verification & Troubleshooting

### How many rows loaded?
Right after `COPY INTO`:
```sql
SELECT SUM(TO_NUMBER(rows_loaded)) AS total_rows_loaded
FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()));
```

Count in the table:
```sql
SELECT COUNT(*) AS total_rows_in_table
FROM OUR_FIRST_DB.PUBLIC.ORDERS_EX;
```

Recent copy history:
```sql
SELECT *
FROM TABLE(
  INFORMATION_SCHEMA.COPY_HISTORY(
    TABLE_NAME => 'OUR_FIRST_DB.PUBLIC.ORDERS_EX',
    START_TIME => DATEADD('hour', -1, CURRENT_TIMESTAMP())
  )
)
ORDER BY START_TIME DESC;
```

### Common pitfalls
- **Column order mismatch**: The order in your target list must match the order of fields output by the `SELECT`.
- **Type issues**: Cast `VARCHAR` → `NUMBER` or `DATE` explicitly (`TRY_TO_NUMBER`, `TO_DATE`, etc.).
- **Header not skipped**: Make sure `SKIP_HEADER = 1` for headered files.
- **Wrong file**: If you see no rows loaded, double-check the `FILES=('OrderDetails.csv')` path (case/relative path).
- **Replaced table**: Using `CREATE OR REPLACE TABLE` wipes previous data—confirm that’s intended.

---

## 🧠 Key Takeaways

- You can **load a subset of columns** by listing only the target columns in `COPY INTO` and selecting the matching `$N` fields.
- Identity columns (`AUTOINCREMENT`) **auto-populate** if they’re omitted from the target column list.
- Always **cast** CSV fields to the correct types; CSV is text on read.
- Use `RESULT_SCAN(LAST_QUERY_ID())` and `COPY_HISTORY` to **verify** load outcomes.
- Keep your mapping self-documenting with **aliases** and **explicit target lists**.

---

## 🧹 Clean up (optional)
```sql
DROP TABLE OUR_FIRST_DB.PUBLIC.ORDERS_EX;
```
- Removes the table and data (does **not** touch staged files).
